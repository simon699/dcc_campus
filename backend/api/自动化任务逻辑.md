
# 自动化任务逻辑

## 第一步，筛选任务

### 筛选条件
在 call_tasks 中，筛选 `task_type` 为 2/3 的任务：
- **task_type = 2**：外呼开始（已创建 job_group，正在外呼中）
- **task_type = 3**：外呼完成跟进中（外呼已完成，但跟进记录可能未完成）

### 前置条件
- 任务必须已创建（task_type >= 2）
- 任务必须有 `job_group_id`（不为空）

### 输出
- 符合条件的任务列表，包含：task_id、task_name、task_type、job_group_id

## 第二步 获取 call_job_id

### 输入
- task_id：任务ID
- job_group_id：从 call_tasks 表中获取的 job_group_id

### 处理流程

1. **获取 job_group_id**
   - 从 call_tasks 表中查询：`SELECT job_group_id FROM call_tasks WHERE id = task_id`
   - 如果 job_group_id 为空，跳过该任务

2. **分页获取 jobs 列表**
   - 调用阿里云接口：`list_jobs_by_group`（或 `query_jobs_with_result`）
   - 分页参数：page_size = 100，逐页获取所有 jobs
   - 每页处理完成后继续下一页，直到获取完所有数据

3. **匹配策略（优先级从高到低）**
   
   **策略1：reference_id 精确匹配（新任务）**
   - 如果 leads_task_list 中 `reference_id` 不为空
   - 直接使用 `reference_id` 与 jobs 的 `Contacts.ReferenceId` 进行匹配
   - SQL 更新：`UPDATE leads_task_list SET call_job_id = job_id WHERE task_id = X AND reference_id = Y`
   
   **策略2：历史任务回退匹配**
   - 如果 `reference_id` 为空（历史任务可能未写入）
   - 通过规则生成临时 reference_id：`task_{task_id}_lead_{leads_id}`
   - 与 jobs 的 `Contacts.ReferenceId` 进行匹配
   - 匹配成功后写入 `call_job_id`
   
   **策略3：电话匹配回退**
   - 如果 reference_id 匹配失败（0条更新）
   - 使用 `leads_phone` 与 jobs 的 `Contacts.PhoneNumber` 进行匹配
   - SQL 更新：`UPDATE leads_task_list SET call_job_id = job_id WHERE task_id = X AND leads_phone = Y`
   
   **策略4：JobId 直接匹配（兜底）**
   - 如果 JobId 在请求的 call_job_id 列表中，直接使用

4. **未匹配记录处理**
   - 遍历完所有分页数据后
   - 检查 leads_task_list 中 `task_id = 任务ID` 且 `call_job_id` 仍为空的记录
   - 如果该记录有 `reference_id` 或 `leads_phone`，说明应该匹配但未匹配到
   - 将 `call_status` 设置为 `'Failed'`，表示外呼失败

### 输出
- 更新 leads_task_list 表中的 `call_job_id` 字段
- 未匹配的记录设置 `call_status = 'Failed'`

### 错误处理
- 如果 API 调用失败，记录错误日志，可重试（最多3次）
- 如果数据库更新失败，记录错误但不中断流程

## 第三步 获取对话数据

### 输入
- task_id：任务ID
- call_job_id 列表：从 leads_task_list 中查询，**只处理 call_status 为空的记录**

### 处理流程

1. **批量查询 call_job_id 列表（只处理 call_status 为空的记录）**
   - 查询条件：`SELECT call_job_id FROM leads_task_list WHERE task_id = X AND call_job_id IS NOT NULL AND call_job_id != '' AND (call_status IS NULL OR call_status = '')`
   - **重要**：只处理 `call_status` 为空的记录，避免重复处理已有数据的记录
   - 建议批量大小：每批 200 个 call_job_id（避免单次请求过大）

2. **调用阿里云接口获取数据**
   - 调用 `list_jobs` 接口，传入 call_job_id 列表
   - 返回每个 job 的详细信息

3. **提取并更新字段**
   - **call_status**：从 job.Status 或 tasks[-1].Status 获取
   - **call_conversation**：从 tasks[-1].Conversation 获取（JSON格式）
   - **planed_time**：从 tasks[-1].PlanedTime 获取（时间戳转 datetime）
   - **updated_time**：使用当前时间或 tasks[-1].ActualTime
   - **call_task_id**：从 tasks[-1].TaskId 获取（用于后续获取录音）
   - **calling_number**：从 tasks[-1].CallingNumber 获取

4. **批量更新数据库**
   - 使用批量 UPDATE 语句更新 leads_task_list 表
   - 更新条件：`WHERE task_id = X AND call_job_id = Y`

### 输出
- 更新 leads_task_list 表中的以下字段：
  - call_status
  - call_conversation
  - planed_time
  - updated_time
  - call_task_id
  - calling_number

### 前置条件
- 必须已完成第二步（call_job_id 不为空）

### 错误处理
- 如果 API 调用失败，记录错误，可重试
- 如果部分 job_id 未返回数据，记录警告但不中断流程

## 第四步 获取录音

### 输入
- call_task_id：从第三步获取的 call_task_id（不为空）
- call_status：必须是 'Succeeded'（只有成功的通话才有录音）

### 处理流程

1. **筛选需要获取录音的记录**
   - 查询条件：`SELECT call_task_id FROM leads_task_list WHERE call_status = 'Succeeded' AND call_task_id IS NOT NULL AND (recording_url IS NULL OR recording_url = '')`
   - 只处理已成功且录音URL为空的记录

2. **调用阿里云接口获取录音URL**
   - 调用 `download_recording` 接口，传入 `call_task_id`
   - 返回录音文件的下载URL

3. **更新数据库**
   - 更新 leads_task_list 表：`UPDATE leads_task_list SET recording_url = 'URL' WHERE call_task_id = X`

### 输出
- 更新 leads_task_list 表中的 `recording_url` 字段

### 前置条件
- 必须已完成第三步（call_task_id 不为空）
- call_status 必须为 'Succeeded'

### 错误处理
- 如果获取录音失败，保持 recording_url 为空，记录警告
- 如果 call_task_id 无效，跳过该记录

## 第五步 获取跟进记录

### 输入
- call_job_id：从 leads_task_list 中查询
- call_conversation：从第三步获取的对话内容
- call_status：外呼状态

### 处理流程

1. **筛选需要创建跟进记录的数据**
   - 查询条件：`SELECT call_job_id, call_conversation, call_status, leads_id FROM leads_task_list WHERE call_job_id IS NOT NULL AND leads_follow_id IS NULL`
   - 只处理有 call_job_id 但未创建跟进记录的数据

2. **判断是否需要AI分析**
   
   **情况A：有 call_conversation 且有值**
   - 调用 `ali_bailian_api`，传入 call_conversation（JSON格式）
   - AI 返回：
     - `leads_remark`：跟进备注
     - `is_interested`：意向判断（0=无法判断，1=有意向，2=无意向）
     - `next_follow_time`：下次跟进时间（可选）
   
   **情况B：call_conversation 为空但 call_status 有值**
   - 根据 call_status 设置默认值：
     - `call_status = 'Failed'`：设置 `is_interested = 0`，`leads_remark = '呼叫失败；'`
     - `call_status = 'Succeeded'`：设置 `is_interested = 0`，`leads_remark = '外呼已完成，但暂无通话内容；'`
     - 其他状态：设置 `is_interested = 0`，`leads_remark = f'外呼状态：{call_status}；'`
   
   **情况C：call_status 为空**
   - 跳过，等待获取到 call_status 后再处理

3. **创建跟进记录**
   - 插入 dcc_leads_follow 表：
     ```sql
     INSERT INTO dcc_leads_follow 
     (leads_id, follow_time, leads_remark, frist_follow_time, new_follow_time, next_follow_time)
     VALUES (leads_id, NOW(), leads_remark, NOW(), NOW(), next_follow_time)
     ```
   - 获取插入后的 follow_id

4. **更新 leads_task_list**
   - 更新字段：
     ```sql
     UPDATE leads_task_list 
     SET leads_follow_id = follow_id, is_interested = is_interested
     WHERE call_job_id = call_job_id
     ```

### 输出
- 在 dcc_leads_follow 表中创建新记录
- 更新 leads_task_list 表中的 `leads_follow_id` 和 `is_interested` 字段

### 前置条件
- 必须已完成第三步（call_status 不为空）
- call_job_id 必须存在

### 错误处理
- 如果 AI 调用失败，创建基本跟进记录（is_interested = 0）
- 如果数据库插入失败，记录错误并重试 

## 结果判断与状态更新

### 判断条件1：外呼完成（task_type = 3）

**判断逻辑**
- 查询条件：统计 `task_id = 任务ID` 的所有记录
- 统计已外呼的记录：`call_job_id IS NOT NULL AND call_job_id != ''`
- 统计已外呼且 call_status 有值的记录：`call_job_id IS NOT NULL AND call_status IS NOT NULL AND call_status != ''`

**更新条件**
- 如果：`已外呼记录数 > 0` 且 `已外呼记录数 == 已外呼且call_status有值的记录数`
- 则：`UPDATE call_tasks SET task_type = 3 WHERE id = task_id`
- 含义：所有已外呼的记录都已获取到状态（成功或失败），外呼阶段完成

### 判断条件2：跟进完成（task_type = 4）

**判断逻辑**
- 查询条件：统计 `task_id = 任务ID` 的所有记录
- 统计已外呼的记录：`call_job_id IS NOT NULL AND call_job_id != ''`
- 统计已外呼且 is_interested 有值的记录：`call_job_id IS NOT NULL AND is_interested IS NOT NULL`

**更新条件**
- 如果：`已外呼记录数 > 0` 且 `已外呼记录数 == 已外呼且is_interested有值的记录数`
- 则：`UPDATE call_tasks SET task_type = 4 WHERE id = task_id`
- 含义：所有已外呼的记录都已创建跟进记录，跟进阶段完成

### 注意事项
- 只统计已外呼的记录（call_job_id 不为空）
- 未外呼的记录（call_job_id 为空）不参与判断
- 状态更新是递增的（不能从高状态回退到低状态）

# 并行处理实现方案

## 并行策略

### 1. 第二步内部并行（分页并行）

**问题**：job_group_id 可能包含大量 jobs（数千条），逐页串行处理较慢

**方案**：
- 获取总页数后，将不同页的数据并行处理
- 使用 Celery 任务队列，每个分页作为一个独立任务
- 任务队列：`sync_queue`
- 并发控制：每个任务处理一页数据（100条），避免单任务过大

**实现示例**：
```python
# 获取总页数
total_pages = (total_jobs + page_size - 1) // page_size

# 并行处理各页
for page in range(1, total_pages + 1):
    sync_call_job_ids.delay(task_id, job_group_id, page)
```

### 2. 第二步与第三步并行（流水线处理）

**问题**：等待第二步全部完成后再执行第三步，延迟较大

**方案**：
- 第二步每处理完一批 call_job_id，立即触发第三步处理
- 使用事件驱动或消息队列，第二步完成后发送事件
- 第三步监听事件，收到后立即处理

**实现示例**：
```python
# 第二步处理完一页后
async def sync_call_job_ids_from_group(task_id, job_group_id, page):
    # ... 处理当前页 ...
    # 处理完成后，立即触发第三步
    query_task_execution.delay(task_id, call_job_ids_batch)
```

### 3. 第三步结果并行处理（第四步和第五步并行）

**问题**：第三步获取到数据后，需要等待全部处理完才能执行后续步骤

**重要优化**：
- **先筛选 call_status 为空的记录**：第三步只处理 `call_status IS NULL OR call_status = ''` 的记录
- 避免重复处理已有数据的记录，提高处理效率
- 查询条件：`WHERE task_id = X AND call_job_id IS NOT NULL AND call_job_id != '' AND (call_status IS NULL OR call_status = '')`

**方案**：
- 第三步每获取到一条记录的数据，立即并行触发第四步和第五步
- 第四步和第五步相互独立，可以同时执行
- 使用不同的 Celery 队列：
  - `download_queue`：处理录音下载（第四步）
  - `ai_queue`：处理AI分析（第五步的一部分）
  - `follow_queue`：处理跟进记录创建（第五步）

**实现示例**：
```python
# 第三步：先筛选 call_status 为空的记录
count_query = """
    SELECT COUNT(*) as total
    FROM leads_task_list 
    WHERE task_id = %s 
      AND call_job_id IS NOT NULL 
      AND call_job_id != ''
      AND (call_status IS NULL OR call_status = '')
"""

# 第三步获取到数据后
for job_data in jobs_data:
    call_job_id = job_data['JobId']
    call_task_id = job_data['Tasks'][-1]['TaskId']
    call_conversation = job_data['Tasks'][-1]['Conversation']
    
    # 并行触发第四步和第五步
    if call_status == 'Succeeded' and call_task_id:
        download_recording.delay(call_task_id, call_job_id)  # 第四步
    
    if call_conversation:
        generate_follow.delay(call_job_id)  # 第五步（AI分析）
        create_leads_follow.delay(call_job_id)  # 第五步（创建跟进）
```

## 并发控制机制

### 1. 任务去重
- 使用 Redis 记录正在处理的任务ID
- 避免同一任务被重复处理
- 键格式：`processing:task:{task_id}` 或 `processing:call_job_id:{call_job_id}`

### 2. 任务优先级
- 使用 Celery 任务优先级机制
- 关键任务设置更高优先级
- 配置示例：
  ```python
  task_routes = {
      'sync_call_job_ids': {'queue': 'sync_queue', 'priority': 5},
      'query_task_execution': {'queue': 'query_queue', 'priority': 6},
      'download_recording': {'queue': 'download_queue', 'priority': 3},
      'generate_follow': {'queue': 'ai_queue', 'priority': 4},
  }
  ```

### 3. 错误处理和重试
- 所有任务支持自动重试（最多3次）
- 重试延迟：60-120秒
- 失败后记录日志，不影响其他任务

### 4. 资源限制
- Worker 并发数：根据服务器资源配置（建议4-8个）
- 队列大小：监控队列长度，避免积压
- API 限流：控制对阿里云API的调用频率

## 性能优化建议

1. **批量处理**：尽量使用批量接口和批量更新
2. **缓存机制**：缓存任务信息，避免重复查询数据库
3. **异步处理**：所有耗时操作使用异步任务
4. **监控告警**：监控任务执行时间、失败率、队列长度
5. **分片处理**：大任务拆分成多个小任务并行处理

# 补充说明

## reference_id 生成规则

### 新任务（创建时写入）
- **格式**：`{task_id}{organization_id}{leads_id}`
- **时机**：创建任务时，在 `create_auto_call_task_service` 中批量插入 leads_task_list 时写入
- **用途**：用于后续与阿里云返回的 job 进行精确匹配

### 历史任务匹配规则
- **格式**：`task_{task_id}_lead_{leads_id}`
- **时机**：当 reference_id 为空时（历史任务可能未写入 reference_id），用于匹配阿里云返回的 job
- **用途**：兼容历史数据，通过规则生成临时 reference_id 进行匹配